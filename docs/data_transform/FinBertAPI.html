<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, minimum-scale=1"
    />
    <meta name="generator" content="pdoc 0.10.0" />
    <title>data_transform.FinBertAPI API documentation</title>
    <meta name="description" content="" />
    <link
      rel="preload stylesheet"
      as="style"
      href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css"
      integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs="
      crossorigin
    />
    <link
      rel="preload stylesheet"
      as="style"
      href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css"
      integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg="
      crossorigin
    />
    <link
      rel="stylesheet preload"
      as="style"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css"
      crossorigin
    />
    <style>
      :root {
        --highlight-color: #fe9;
      }
      .flex {
        display: flex !important;
      }
      body {
        line-height: 1.5em;
      }
      #content {
        padding: 20px;
      }
      #sidebar {
        padding: 30px;
        overflow: hidden;
      }
      #sidebar > *:last-child {
        margin-bottom: 2cm;
      }
      .http-server-breadcrumbs {
        font-size: 130%;
        margin: 0 0 15px 0;
      }
      #footer {
        font-size: 0.75em;
        padding: 5px 30px;
        border-top: 1px solid #ddd;
        text-align: right;
      }
      #footer p {
        margin: 0 0 0 1em;
        display: inline-block;
      }
      #footer p:last-child {
        margin-right: 30px;
      }
      h1,
      h2,
      h3,
      h4,
      h5 {
        font-weight: 300;
      }
      h1 {
        font-size: 2.5em;
        line-height: 1.1em;
      }
      h2 {
        font-size: 1.75em;
        margin: 1em 0 0.5em 0;
      }
      h3 {
        font-size: 1.4em;
        margin: 25px 0 10px 0;
      }
      h4 {
        margin: 0;
        font-size: 105%;
      }
      h1:target,
      h2:target,
      h3:target,
      h4:target,
      h5:target,
      h6:target {
        background: var(--highlight-color);
        padding: 0.2em 0;
      }
      a {
        color: #058;
        text-decoration: none;
        transition: color 0.3s ease-in-out;
      }
      a:hover {
        color: #e82;
      }
      .title code {
        font-weight: bold;
      }
      h2[id^="header-"] {
        margin-top: 2em;
      }
      .ident {
        color: #900;
      }
      pre code {
        background: #f8f8f8;
        font-size: 0.8em;
        line-height: 1.4em;
      }
      code {
        background: #f2f2f1;
        padding: 1px 4px;
        overflow-wrap: break-word;
      }
      h1 code {
        background: transparent;
      }
      pre {
        background: #f8f8f8;
        border: 0;
        border-top: 1px solid #ccc;
        border-bottom: 1px solid #ccc;
        margin: 1em 0;
        padding: 1ex;
      }
      #http-server-module-list {
        display: flex;
        flex-flow: column;
      }
      #http-server-module-list div {
        display: flex;
      }
      #http-server-module-list dt {
        min-width: 10%;
      }
      #http-server-module-list p {
        margin-top: 0;
      }
      .toc ul,
      #index {
        list-style-type: none;
        margin: 0;
        padding: 0;
      }
      #index code {
        background: transparent;
      }
      #index h3 {
        border-bottom: 1px solid #ddd;
      }
      #index ul {
        padding: 0;
      }
      #index h4 {
        margin-top: 0.6em;
        font-weight: bold;
      }
      @media (min-width: 200ex) {
        #index .two-column {
          column-count: 2;
        }
      }
      @media (min-width: 300ex) {
        #index .two-column {
          column-count: 3;
        }
      }
      dl {
        margin-bottom: 2em;
      }
      dl dl:last-child {
        margin-bottom: 4em;
      }
      dd {
        margin: 0 0 1em 3em;
      }
      #header-classes + dl > dd {
        margin-bottom: 3em;
      }
      dd dd {
        margin-left: 2em;
      }
      dd p {
        margin: 10px 0;
      }
      .name {
        background: #eee;
        font-weight: bold;
        font-size: 0.85em;
        padding: 5px 10px;
        display: inline-block;
        min-width: 40%;
      }
      .name:hover {
        background: #e0e0e0;
      }
      dt:target .name {
        background: var(--highlight-color);
      }
      .name > span:first-child {
        white-space: nowrap;
      }
      .name.class > span:nth-child(2) {
        margin-left: 0.4em;
      }
      .inherited {
        color: #999;
        border-left: 5px solid #eee;
        padding-left: 1em;
      }
      .inheritance em {
        font-style: normal;
        font-weight: bold;
      }
      .desc h2 {
        font-weight: 400;
        font-size: 1.25em;
      }
      .desc h3 {
        font-size: 1em;
      }
      .desc dt code {
        background: inherit;
      }
      .source summary,
      .git-link-div {
        color: #666;
        text-align: right;
        font-weight: 400;
        font-size: 0.8em;
        text-transform: uppercase;
      }
      .source summary > * {
        white-space: nowrap;
        cursor: pointer;
      }
      .git-link {
        color: inherit;
        margin-left: 1em;
      }
      .source pre {
        max-height: 500px;
        overflow: auto;
        margin: 0;
      }
      .source pre code {
        font-size: 12px;
        overflow: visible;
      }
      .hlist {
        list-style: none;
      }
      .hlist li {
        display: inline;
      }
      .hlist li:after {
        content: ",\2002";
      }
      .hlist li:last-child:after {
        content: none;
      }
      .hlist .hlist {
        display: inline;
        padding-left: 1em;
      }
      img {
        max-width: 100%;
      }
      td {
        padding: 0 0.5em;
      }
      .admonition {
        padding: 0.1em 0.5em;
        margin-bottom: 1em;
      }
      .admonition-title {
        font-weight: bold;
      }
      .admonition.note,
      .admonition.info,
      .admonition.important {
        background: #aef;
      }
      .admonition.todo,
      .admonition.versionadded,
      .admonition.tip,
      .admonition.hint {
        background: #dfd;
      }
      .admonition.warning,
      .admonition.versionchanged,
      .admonition.deprecated {
        background: #fd4;
      }
      .admonition.error,
      .admonition.danger,
      .admonition.caution {
        background: lightpink;
      }
    </style>
    <style media="screen and (min-width: 700px)">
      @media screen and (min-width: 700px) {
        #sidebar {
          width: 30%;
          height: 100vh;
          overflow: auto;
          position: sticky;
          top: 0;
        }
        #content {
          width: 70%;
          max-width: 100ch;
          padding: 3em 4em;
          border-left: 1px solid #ddd;
        }
        pre code {
          font-size: 1em;
        }
        .item .name {
          font-size: 1em;
        }
        main {
          display: flex;
          flex-direction: row-reverse;
          justify-content: flex-end;
        }
        .toc ul ul,
        #index ul {
          padding-left: 1.5em;
        }
        .toc > ul > li {
          margin-top: 0.5em;
        }
      }
    </style>
    <style media="print">
      @media print {
        #sidebar h1 {
          page-break-before: always;
        }
        .source {
          display: none;
        }
      }
      @media print {
        * {
          background: transparent !important;
          color: #000 !important;
          box-shadow: none !important;
          text-shadow: none !important;
        }
        a[href]:after {
          content: " (" attr(href) ")";
          font-size: 90%;
        }
        a[href][title]:after {
          content: none;
        }
        abbr[title]:after {
          content: " (" attr(title) ")";
        }
        .ir a:after,
        a[href^="javascript:"]:after,
        a[href^="#"]:after {
          content: "";
        }
        pre,
        blockquote {
          border: 1px solid #999;
          page-break-inside: avoid;
        }
        thead {
          display: table-header-group;
        }
        tr,
        img {
          page-break-inside: avoid;
        }
        img {
          max-width: 100% !important;
        }
        @page {
          margin: 0.5cm;
        }
        p,
        h2,
        h3 {
          orphans: 3;
          widows: 3;
        }
        h1,
        h2,
        h3,
        h4,
        h5,
        h6 {
          page-break-after: avoid;
        }
      }
    </style>
    <script
      defer
      src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"
      integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8="
      crossorigin
    ></script>
    <script>
      window.addEventListener("DOMContentLoaded", () =>
        hljs.initHighlighting()
      );
    </script>
  </head>
  <body>
    <main>
      <article id="content">
        <header>
          <h1 class="title">Module <code>data_transform.FinBertAPI</code></h1>
        </header>
        <section id="section-intro">
          <details class="source">
            <summary>
              <span>Expand source code</span>
            </summary>
            <pre><code class="python">from matplotlib.pyplot import text
import pandas as pd
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import gc


class FinBERT:
    def __init__(self):
        print(&#34;INFO: Initialising FinBERT model&#34;)
        self.tokenizer = AutoTokenizer.from_pretrained(&#34;ProsusAI/finbert&#34;)
        self.model = AutoModelForSequenceClassification.from_pretrained(
            &#34;ProsusAI/finbert&#34;)
        self.batch_size = 1
        print(&#34;INFO: FinBERT model initialised&#34;)

    def load_text_data(self, text_series):
        &#34;&#34;&#34;This function takes in a Pandas Series of String data, and stores it as a class variable

        Args:
            text_series (pandas.Series): A Series of String

        Raises:
            Exception: Exception when input type is not Series

        Returns:
            list: Returns a list of String chunks
        &#34;&#34;&#34;
        if not isinstance(text_series, pd.core.series.Series):
            raise Exception(&#34;ERROR: Input text not in Series!&#34;)
        else:
            print(&#34;INFO: Loading text data&#34;)
            text_array = np.array(text_series)
            text_list = list(text_array)
            print(&#34;SUCCESS: Text data loaded&#34;)
            return text_list

    def tokenize_text(self, text_list):
        &#34;&#34;&#34;Tokenizes a list of String to prepare for FinBERT model analysis.

        Args:
            text_list (list): a list of Strings

        Returns:
            transformers.tokenization_utils_base.BatchEncoding: tensors of tokenized text
        &#34;&#34;&#34;
        print(&#34;INFO: Tokenizing Text&#34;)
        return self.tokenizer(text_list, padding=True, truncation=True, return_tensors=&#39;pt&#39;)

    def predict_sentiments(self, text_list, inputs):
        &#34;&#34;&#34;Predicts the sentiments of a given input of tokens.

        Args:
            text_list (list): list of text chunks
            inputs (transformers.tokenization_utils_base.BatchEncoding): input tensors of tokens

        Returns:
            pd.DataFrame: returns a DataFrame of text along with the corresponding sentiment scores (Positive, Negative, Neutral)
        &#34;&#34;&#34;
        print(&#34;INFO: Predicting sentiments&#34;)
        outputs = self.model(**inputs)
        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
        print(&#34;SUCCESS: Sentiments successfully predicted&#34;)
        positive = predictions[:, 0].tolist()
        negative = predictions[:, 1].tolist()
        neutral = predictions[:, 2].tolist()
        table = {&#39;Text&#39;: text_list,
                 &#34;Positive&#34;: positive,
                 &#34;Negative&#34;: negative,
                 &#34;Neutral&#34;: neutral}

        df = pd.DataFrame(
            table, columns=[&#34;Text&#34;, &#34;Positive&#34;, &#34;Negative&#34;, &#34;Neutral&#34;])

        return df

    def FinBert_pipeline(self, text_series):
        &#34;&#34;&#34;Executes the FinBert analysis pipeline given an input Series of text. The chunk size can be modified based on system memory capacity.

        Args:
            text_series (pd.Series): input Series of text to be passed in FinBERT sentiment analysis

        Returns:
            pd.DataFrame: returns a DataFrame of text along with the corresponding sentiment scores
        &#34;&#34;&#34;
        predictions_mega = pd.DataFrame(
            columns=[&#34;Text&#34;, &#34;Positive&#34;, &#34;Negative&#34;, &#34;Neutral&#34;])
        if len(text_series) == 0:
            return predictions_mega
        if len(text_series) &lt; self.batch_size:
            self.batch_size = max(len(text_series), 1)
        chunks = np.array_split(text_series, len(text_series)/self.batch_size)
        chunk_counter = 1
        total_chunks = len(chunks)
        for chunk in chunks:
            print(
                f&#34;INFO: Performing FinBERT Analysis on Chunk {chunk_counter} / {total_chunks}&#34;)
            text_list = self.load_text_data(chunk)
            if not text_list[0]:
                predictions = pd.DataFrame(
                    columns=[&#34;Text&#34;, &#34;Positive&#34;, &#34;Negative&#34;, &#34;Neutral&#34;])
                predictions.loc[len(predictions)] = 0
            else:
                tokenized = self.tokenize_text(text_list)
                predictions = self.predict_sentiments(text_list, tokenized)

            predictions_mega = pd.concat([predictions_mega, predictions])
            gc.collect()
            chunk_counter += 1

        print(&#34;SUCCESS: FinBERT analysis completed&#34;)
        return predictions_mega</code></pre>
          </details>
        </section>
        <section></section>
        <section></section>
        <section></section>
        <section>
          <h2 class="section-title" id="header-classes">Classes</h2>
          <dl>
            <dt id="data_transform.FinBertAPI.FinBERT">
              <code class="flex name class">
                <span>class <span class="ident">FinBERT</span></span>
              </code>
            </dt>
            <dd>
              <div class="desc"></div>
              <details class="source">
                <summary>
                  <span>Expand source code</span>
                </summary>
                <pre><code class="python">class FinBERT:
    def __init__(self):
        print(&#34;INFO: Initialising FinBERT model&#34;)
        self.tokenizer = AutoTokenizer.from_pretrained(&#34;ProsusAI/finbert&#34;)
        self.model = AutoModelForSequenceClassification.from_pretrained(
            &#34;ProsusAI/finbert&#34;)
        self.batch_size = 1
        print(&#34;INFO: FinBERT model initialised&#34;)

    def load_text_data(self, text_series):
        &#34;&#34;&#34;This function takes in a Pandas Series of String data, and stores it as a class variable

        Args:
            text_series (pandas.Series): A Series of String

        Raises:
            Exception: Exception when input type is not Series

        Returns:
            list: Returns a list of String chunks
        &#34;&#34;&#34;
        if not isinstance(text_series, pd.core.series.Series):
            raise Exception(&#34;ERROR: Input text not in Series!&#34;)
        else:
            print(&#34;INFO: Loading text data&#34;)
            text_array = np.array(text_series)
            text_list = list(text_array)
            print(&#34;SUCCESS: Text data loaded&#34;)
            return text_list

    def tokenize_text(self, text_list):
        &#34;&#34;&#34;Tokenizes a list of String to prepare for FinBERT model analysis.

        Args:
            text_list (list): a list of Strings

        Returns:
            transformers.tokenization_utils_base.BatchEncoding: tensors of tokenized text
        &#34;&#34;&#34;
        print(&#34;INFO: Tokenizing Text&#34;)
        return self.tokenizer(text_list, padding=True, truncation=True, return_tensors=&#39;pt&#39;)

    def predict_sentiments(self, text_list, inputs):
        &#34;&#34;&#34;Predicts the sentiments of a given input of tokens.

        Args:
            text_list (list): list of text chunks
            inputs (transformers.tokenization_utils_base.BatchEncoding): input tensors of tokens

        Returns:
            pd.DataFrame: returns a DataFrame of text along with the corresponding sentiment scores (Positive, Negative, Neutral)
        &#34;&#34;&#34;
        print(&#34;INFO: Predicting sentiments&#34;)
        outputs = self.model(**inputs)
        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
        print(&#34;SUCCESS: Sentiments successfully predicted&#34;)
        positive = predictions[:, 0].tolist()
        negative = predictions[:, 1].tolist()
        neutral = predictions[:, 2].tolist()
        table = {&#39;Text&#39;: text_list,
                 &#34;Positive&#34;: positive,
                 &#34;Negative&#34;: negative,
                 &#34;Neutral&#34;: neutral}

        df = pd.DataFrame(
            table, columns=[&#34;Text&#34;, &#34;Positive&#34;, &#34;Negative&#34;, &#34;Neutral&#34;])

        return df

    def FinBert_pipeline(self, text_series):
        &#34;&#34;&#34;Executes the FinBert analysis pipeline given an input Series of text. The chunk size can be modified based on system memory capacity.

        Args:
            text_series (pd.Series): input Series of text to be passed in FinBERT sentiment analysis

        Returns:
            pd.DataFrame: returns a DataFrame of text along with the corresponding sentiment scores
        &#34;&#34;&#34;
        predictions_mega = pd.DataFrame(
            columns=[&#34;Text&#34;, &#34;Positive&#34;, &#34;Negative&#34;, &#34;Neutral&#34;])
        if len(text_series) == 0:
            return predictions_mega
        if len(text_series) &lt; self.batch_size:
            self.batch_size = max(len(text_series), 1)
        chunks = np.array_split(text_series, len(text_series)/self.batch_size)
        chunk_counter = 1
        total_chunks = len(chunks)
        for chunk in chunks:
            print(
                f&#34;INFO: Performing FinBERT Analysis on Chunk {chunk_counter} / {total_chunks}&#34;)
            text_list = self.load_text_data(chunk)
            if not text_list[0]:
                predictions = pd.DataFrame(
                    columns=[&#34;Text&#34;, &#34;Positive&#34;, &#34;Negative&#34;, &#34;Neutral&#34;])
                predictions.loc[len(predictions)] = 0
            else:
                tokenized = self.tokenize_text(text_list)
                predictions = self.predict_sentiments(text_list, tokenized)

            predictions_mega = pd.concat([predictions_mega, predictions])
            gc.collect()
            chunk_counter += 1

        print(&#34;SUCCESS: FinBERT analysis completed&#34;)
        return predictions_mega</code></pre>
              </details>
              <h3>Methods</h3>
              <dl>
                <dt id="data_transform.FinBertAPI.FinBERT.FinBert_pipeline">
                  <code class="name flex">
                    <span>def <span class="ident">FinBert_pipeline</span></span
                    >(<span>self, text_series)</span>
                  </code>
                </dt>
                <dd>
                  <div class="desc">
                    <p>
                      Executes the FinBert analysis pipeline given an input
                      Series of text. The chunk size can be modified based on
                      system memory capacity.
                    </p>
                    <h2 id="args">Args</h2>
                    <dl>
                      <dt>
                        <strong><code>text_series</code></strong> :&ensp;<code
                          >pd.Series</code
                        >
                      </dt>
                      <dd>
                        input Series of text to be passed in FinBERT sentiment
                        analysis
                      </dd>
                    </dl>
                    <h2 id="returns">Returns</h2>
                    <dl>
                      <dt><code>pd.DataFrame</code></dt>
                      <dd>
                        returns a DataFrame of text along with the corresponding
                        sentiment scores
                      </dd>
                    </dl>
                  </div>
                  <details class="source">
                    <summary>
                      <span>Expand source code</span>
                    </summary>
                    <pre><code class="python">def FinBert_pipeline(self, text_series):
    &#34;&#34;&#34;Executes the FinBert analysis pipeline given an input Series of text. The chunk size can be modified based on system memory capacity.

    Args:
        text_series (pd.Series): input Series of text to be passed in FinBERT sentiment analysis

    Returns:
        pd.DataFrame: returns a DataFrame of text along with the corresponding sentiment scores
    &#34;&#34;&#34;
    predictions_mega = pd.DataFrame(
        columns=[&#34;Text&#34;, &#34;Positive&#34;, &#34;Negative&#34;, &#34;Neutral&#34;])
    if len(text_series) == 0:
        return predictions_mega
    if len(text_series) &lt; self.batch_size:
        self.batch_size = max(len(text_series), 1)
    chunks = np.array_split(text_series, len(text_series)/self.batch_size)
    chunk_counter = 1
    total_chunks = len(chunks)
    for chunk in chunks:
        print(
            f&#34;INFO: Performing FinBERT Analysis on Chunk {chunk_counter} / {total_chunks}&#34;)
        text_list = self.load_text_data(chunk)
        if not text_list[0]:
            predictions = pd.DataFrame(
                columns=[&#34;Text&#34;, &#34;Positive&#34;, &#34;Negative&#34;, &#34;Neutral&#34;])
            predictions.loc[len(predictions)] = 0
        else:
            tokenized = self.tokenize_text(text_list)
            predictions = self.predict_sentiments(text_list, tokenized)

        predictions_mega = pd.concat([predictions_mega, predictions])
        gc.collect()
        chunk_counter += 1

    print(&#34;SUCCESS: FinBERT analysis completed&#34;)
    return predictions_mega</code></pre>
                  </details>
                </dd>
                <dt id="data_transform.FinBertAPI.FinBERT.load_text_data">
                  <code class="name flex">
                    <span>def <span class="ident">load_text_data</span></span
                    >(<span>self, text_series)</span>
                  </code>
                </dt>
                <dd>
                  <div class="desc">
                    <p>
                      This function takes in a Pandas Series of String data, and
                      stores it as a class variable
                    </p>
                    <h2 id="args">Args</h2>
                    <dl>
                      <dt>
                        <strong><code>text_series</code></strong> :&ensp;<code
                          >pandas.Series</code
                        >
                      </dt>
                      <dd>A Series of String</dd>
                    </dl>
                    <h2 id="raises">Raises</h2>
                    <dl>
                      <dt><code>Exception</code></dt>
                      <dd>Exception when input type is not Series</dd>
                    </dl>
                    <h2 id="returns">Returns</h2>
                    <dl>
                      <dt><code>list</code></dt>
                      <dd>Returns a list of String chunks</dd>
                    </dl>
                  </div>
                  <details class="source">
                    <summary>
                      <span>Expand source code</span>
                    </summary>
                    <pre><code class="python">def load_text_data(self, text_series):
    &#34;&#34;&#34;This function takes in a Pandas Series of String data, and stores it as a class variable

    Args:
        text_series (pandas.Series): A Series of String

    Raises:
        Exception: Exception when input type is not Series

    Returns:
        list: Returns a list of String chunks
    &#34;&#34;&#34;
    if not isinstance(text_series, pd.core.series.Series):
        raise Exception(&#34;ERROR: Input text not in Series!&#34;)
    else:
        print(&#34;INFO: Loading text data&#34;)
        text_array = np.array(text_series)
        text_list = list(text_array)
        print(&#34;SUCCESS: Text data loaded&#34;)
        return text_list</code></pre>
                  </details>
                </dd>
                <dt id="data_transform.FinBertAPI.FinBERT.predict_sentiments">
                  <code class="name flex">
                    <span
                      >def <span class="ident">predict_sentiments</span></span
                    >(<span>self, text_list, inputs)</span>
                  </code>
                </dt>
                <dd>
                  <div class="desc">
                    <p>Predicts the sentiments of a given input of tokens.</p>
                    <h2 id="args">Args</h2>
                    <dl>
                      <dt>
                        <strong><code>text_list</code></strong> :&ensp;<code
                          >list</code
                        >
                      </dt>
                      <dd>list of text chunks</dd>
                      <dt>
                        <strong><code>inputs</code></strong> :&ensp;<code
                          >transformers.tokenization_utils_base.BatchEncoding</code
                        >
                      </dt>
                      <dd>input tensors of tokens</dd>
                    </dl>
                    <h2 id="returns">Returns</h2>
                    <dl>
                      <dt><code>pd.DataFrame</code></dt>
                      <dd>
                        returns a DataFrame of text along with the corresponding
                        sentiment scores (Positive, Negative, Neutral)
                      </dd>
                    </dl>
                  </div>
                  <details class="source">
                    <summary>
                      <span>Expand source code</span>
                    </summary>
                    <pre><code class="python">def predict_sentiments(self, text_list, inputs):
    &#34;&#34;&#34;Predicts the sentiments of a given input of tokens.

    Args:
        text_list (list): list of text chunks
        inputs (transformers.tokenization_utils_base.BatchEncoding): input tensors of tokens

    Returns:
        pd.DataFrame: returns a DataFrame of text along with the corresponding sentiment scores (Positive, Negative, Neutral)
    &#34;&#34;&#34;
    print(&#34;INFO: Predicting sentiments&#34;)
    outputs = self.model(**inputs)
    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
    print(&#34;SUCCESS: Sentiments successfully predicted&#34;)
    positive = predictions[:, 0].tolist()
    negative = predictions[:, 1].tolist()
    neutral = predictions[:, 2].tolist()
    table = {&#39;Text&#39;: text_list,
             &#34;Positive&#34;: positive,
             &#34;Negative&#34;: negative,
             &#34;Neutral&#34;: neutral}

    df = pd.DataFrame(
        table, columns=[&#34;Text&#34;, &#34;Positive&#34;, &#34;Negative&#34;, &#34;Neutral&#34;])

    return df</code></pre>
                  </details>
                </dd>
                <dt id="data_transform.FinBertAPI.FinBERT.tokenize_text">
                  <code class="name flex">
                    <span>def <span class="ident">tokenize_text</span></span
                    >(<span>self, text_list)</span>
                  </code>
                </dt>
                <dd>
                  <div class="desc">
                    <p>
                      Tokenizes a list of String to prepare for FinBERT model
                      analysis.
                    </p>
                    <h2 id="args">Args</h2>
                    <dl>
                      <dt>
                        <strong><code>text_list</code></strong> :&ensp;<code
                          >list</code
                        >
                      </dt>
                      <dd>a list of Strings</dd>
                    </dl>
                    <h2 id="returns">Returns</h2>
                    <dl>
                      <dt>
                        <code
                          >transformers.tokenization_utils_base.BatchEncoding</code
                        >
                      </dt>
                      <dd>tensors of tokenized text</dd>
                    </dl>
                  </div>
                  <details class="source">
                    <summary>
                      <span>Expand source code</span>
                    </summary>
                    <pre><code class="python">def tokenize_text(self, text_list):
    &#34;&#34;&#34;Tokenizes a list of String to prepare for FinBERT model analysis.

    Args:
        text_list (list): a list of Strings

    Returns:
        transformers.tokenization_utils_base.BatchEncoding: tensors of tokenized text
    &#34;&#34;&#34;
    print(&#34;INFO: Tokenizing Text&#34;)
    return self.tokenizer(text_list, padding=True, truncation=True, return_tensors=&#39;pt&#39;)</code></pre>
                  </details>
                </dd>
              </dl>
            </dd>
          </dl>
        </section>
      </article>
      <nav id="sidebar">
        <h1>Index</h1>
        <div class="toc">
          <ul></ul>
        </div>
        <ul id="index">
          <li>
            <h3>Super-module</h3>
            <ul>
              <li>
                <code
                  ><a title="Syfr_API" href="../index.html"
                    >Syfr API Documentation</a
                  ></code
                >
              </li>
              <li>
                <code
                  ><a title="data_transform" href="index.html"
                    >data_transform</a
                  ></code
                >
              </li>
            </ul>
          </li>
          <li>
            <h3><a href="#header-classes">Classes</a></h3>
            <ul>
              <li>
                <h4>
                  <code
                    ><a
                      title="data_transform.FinBertAPI.FinBERT"
                      href="#data_transform.FinBertAPI.FinBERT"
                      >FinBERT</a
                    ></code
                  >
                </h4>
                <ul class="">
                  <li>
                    <code
                      ><a
                        title="data_transform.FinBertAPI.FinBERT.FinBert_pipeline"
                        href="#data_transform.FinBertAPI.FinBERT.FinBert_pipeline"
                        >FinBert_pipeline</a
                      ></code
                    >
                  </li>
                  <li>
                    <code
                      ><a
                        title="data_transform.FinBertAPI.FinBERT.load_text_data"
                        href="#data_transform.FinBertAPI.FinBERT.load_text_data"
                        >load_text_data</a
                      ></code
                    >
                  </li>
                  <li>
                    <code
                      ><a
                        title="data_transform.FinBertAPI.FinBERT.predict_sentiments"
                        href="#data_transform.FinBertAPI.FinBERT.predict_sentiments"
                        >predict_sentiments</a
                      ></code
                    >
                  </li>
                  <li>
                    <code
                      ><a
                        title="data_transform.FinBertAPI.FinBERT.tokenize_text"
                        href="#data_transform.FinBertAPI.FinBERT.tokenize_text"
                        >tokenize_text</a
                      ></code
                    >
                  </li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </nav>
    </main>
    <footer id="footer">
      <p>
        Generated by
        <a
          href="https://pdoc3.github.io/pdoc"
          title="pdoc: Python API documentation generator"
          ><cite>pdoc</cite> 0.10.0</a
        >.
      </p>
    </footer>
  </body>
</html>
